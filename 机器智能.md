# 机器智能

## 第二章 智能Agent

Agent函数描述了Agent的行为，它讲任意给定感知序列映射为行动。

### 理性Agent

Agent产生行为并选择是器能性能度量最大化的行动。

### 任务环境(PEAS)四要素： 

- 性能(Performance) 

- 环境(Environment) 

- 执行器(Actuators) 

- 传感器(Sensors)

完全可观察与部分可观察：能否获取环境的完整状态

单Agent和多Agent：

确定的和随机的：环境的下一这状态是否完全取决于当前状态和Agent行为

片段式的与延续式的：下一个片段是否依赖于以前采取的行动

静态的与动态的：Agent在计算式是否会变化

离散的和连续的：环境的状态、时间的处理方式和Agent感知信息和行动是否连续

已知的与未知的：环境是否已知

### Agent结构

Agent=体系结构+程序

Agent仅仅以当前感知为输入而不是以整个历史感知为输入

### Agent的类型

1. 简单反射agent
   基于当前的感知选择行动，不关注感知历史
2.  基于模型的反射agent 
   - Agent根据感知历史维持内部状态 
   - Agent随时更新内部状态信息
3. 基于目标的agent 
   除了根据感知信息之外，还要根据目标信息来选择行动
4. 基于效用(utility)的agent
   - 当达到目标的行为有很多种的时候，需要考虑效用
   - 环境是部分可观察的和随机的，不确定下的决策过程可以通过基于效用的agent来实现。
5. 学习Agent
   - 性能元件：相当于整个agent 
   - 评判元件：反映性能元件做得如何 
   - 学习元件：负责改进提高 
   - 问题产生器：提出一些新的有建设性的探索、尝试

## 第三章 Part1通过搜索进行问题求解（无信息）

问题求解Agent是基于目标的Agent的一种。

无信息是指算法除了问题定义本身以外没有任何其他信息。

搜索问题求解agent 

- 形式化 
- 搜索 
- 执行

### 良定义的问题及解

一个问题包含以下五个组成部分

- Agent的初始状态：In(Arad)
- Agent的可能行动：{Go(Sibiu),Go(Timisoara),Go(Zerind)}
- 转移模型：Result(In(Arad),Go(Zerind))=In(Zerind)
- 目标测试：{In(Bucharest)}
- 路径耗散：c(s,a,s’)采用行动a从s移动到s‘

### 树搜索算法

树表示：

- 根节点：初始状态
- 连线：行动
- 结点：状态空间中的状态

性能评价标准 

- 完备性：如果问题存在解，算法即可找到解
- 最优性：找到的解是最优解
- 时间复杂度：花费的时间
- 空间复杂度：花费的内存

### 搜索策略

1. 宽度优先搜索：FIFO队列实现
   先扩展根结点，再扩展根结点的所有后继， 然后再扩展它们的后继。
   生成目标节点时目标检测（入队之前而不是出队时）
   路径代价非递减时能得到最优解。
2. 一致代价搜索：扩展路径消耗最小的节点
   目标检测用于节点被选择扩展时（出队时）。
   能得到最优解。
3. 深度优先搜索：LIFO栈实现
   首先扩展深度最深的节点。
   **得不到最优解。**
4. 迭代加深的深度优先搜索
   结合了宽度优先和深度优先的特点。
   不断增大深度，同时每次从根节点深搜。
   路径代价非递减时能得到最优解。

总结：

| Criterion | 宽度优先 | 一致代价 | 深度优先 | 迭代加深 |
| --------- | -------- | -------- | -------- | -------- |
| 完备性    | Yes      | Yes      | No       | Yes      |
| Time      | b^d      |          | b^m      | b^d      |
| Space     | b^d      |          | bm       | bd       |

d:最浅深度；m：最深深度;b:分支因子

## 第三章 PART2 有信息搜索策略

### 最佳优先搜索

通过对每一个结点计算评价函数f(n)值,找到一 个f(n)最低的未扩散的结点

大多数评价函数由启发函数h构成 ：h(n)结点到目标结点的最小代价估计值 

#### 贪婪最佳优先搜索

扩展与目标结点估测距离最近的结点。
是不完备的。

#### A*搜索

评价函数

- f(n) = g(n) + h(n)
- g(n)=到达结点n已经花费的代价
- h(n)=结点n到目标节点的评估代价
- f(n)=通过结点n到达目标结点的总评估代价

是完备的，也是最优的。

**启发式函数代价不会超过真实的解代价**

### 启发式搜索性能

对于**所有的结点**n, h2(n)>= h1(n) (两个函数都是可采纳的)，h2(n)比h1(n)有优势。

### 松弛问题

减少了行动限制的问题称为松弛问题。

松弛问题增加了状态空间的边 。

原有问题的任一最优解同样也是松弛问题 的解，但松弛问题可能存在更好的解。

## 第四章 超越经典的搜索

